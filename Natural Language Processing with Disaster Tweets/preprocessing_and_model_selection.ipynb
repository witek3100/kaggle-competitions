{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:13:09.512141300Z",
     "start_time": "2023-08-12T12:13:09.502140500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.drop(columns=['location', 'keyword'], inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.drop(columns=['location', 'keyword'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:13:09.558599100Z",
     "start_time": "2023-08-12T12:13:09.516138700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def seperate_alphanumeric(text):\n",
    "    words = text\n",
    "    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def decontraction(text):\n",
    "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
    "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
    "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
    "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
    "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
    "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    text = re.sub(r'<.*?>',' ',text)\n",
    "    return text\n",
    "\n",
    "def remove_mentions(text):\n",
    "    text = re.sub('@\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_emoji(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_url(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : seperate_alphanumeric(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : decontraction(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_html(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_mentions(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : x.lower())\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_emoji(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_url(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : seperate_alphanumeric(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : decontraction(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_html(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_mentions(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : x.lower())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:13:09.969420400Z",
     "start_time": "2023-08-12T12:13:09.683222700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "text = pd.concat([df_train['text'], df_test['text']], axis=0)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "vectors = tfidf_vectorizer.fit_transform(\n",
    "    text\n",
    ")\n",
    "\n",
    "train_target = df_train['target']\n",
    "test_ids = df_test['id']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:13:10.230490400Z",
     "start_time": "2023-08-12T12:13:09.974190800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "      0      1      2      3      4      5      6      7         8      9      \\\n0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.382083    0.0   \n4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n...     ...    ...    ...    ...    ...    ...    ...    ...       ...    ...   \n7608    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n7609    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n7610    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n7611    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n7612    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000    0.0   \n\n      ...  15357  15358  15359  15360  15361  15362  15363  15364  15365  \\\n0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n7608  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n7609  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n7610  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n7611  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n7612  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n\n      15366  \n0       0.0  \n1       0.0  \n2       0.0  \n3       0.0  \n4       0.0  \n...     ...  \n7608    0.0  \n7609    0.0  \n7610    0.0  \n7611    0.0  \n7612    0.0  \n\n[7613 rows x 15367 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>15357</th>\n      <th>15358</th>\n      <th>15359</th>\n      <th>15360</th>\n      <th>15361</th>\n      <th>15362</th>\n      <th>15363</th>\n      <th>15364</th>\n      <th>15365</th>\n      <th>15366</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.382083</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 15367 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = pd.DataFrame(vectors.toarray())\n",
    "\n",
    "train = vectors.iloc[:7613, :]\n",
    "test = vectors.iloc[7613:, :]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:13:10.311101300Z",
     "start_time": "2023-08-12T12:13:10.230490400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.60615154, 0.56458636, 0.58092486, 0.61582734, 0.65787647])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "scores = cross_val_score(gnb, train, train_target, cv=5, scoring='f1')\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:19:14.514189700Z",
     "start_time": "2023-08-12T12:19:06.104729400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "gnb.fit(train, train_target)\n",
    "predictions = pd.DataFrame(gnb.predict(test))\n",
    "predictions.set_index(test_ids, inplace=True)\n",
    "predictions.to_csv('data/predictions/gaussian-nb.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:16:18.054710500Z",
     "start_time": "2023-08-12T12:16:16.043398800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
