{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-09T20:10:40.446754900Z",
     "start_time": "2023-08-09T20:10:40.437266800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_train.drop(columns=['location', 'keyword'], inplace=True)\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test.drop(columns=['location', 'keyword'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T20:12:47.279723900Z",
     "start_time": "2023-08-09T20:12:47.221095300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0       our deeds are the reason of this earthquake ma...\n1                   forest fire near la ronge sask canada\n2       all residents asked to shelter in place are be...\n3       13 000 people receive wildfires evacuation ord...\n4       just got sent this photo from ruby alaska as s...\n                              ...                        \n7608    two giant cranes holding a bridge collapse int...\n7609    aria ahrary thetawniest the out of control wil...\n7610            m 1 94 01 04 utc 5 km s of volcano hawaii\n7611    police investigating after an e bike collided ...\n7612    the latest more homes razed by northern califo...\nName: text, Length: 7613, dtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def seperate_alphanumeric(text):\n",
    "    words = text\n",
    "    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def decontraction(text):\n",
    "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
    "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
    "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
    "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
    "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
    "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    text = re.sub(r'<.*?>',' ',text)\n",
    "    return text\n",
    "\n",
    "def remove_mentions(text):\n",
    "    text = re.sub('@\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_emoji(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_url(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : seperate_alphanumeric(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : decontraction(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_html(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : remove_mentions(x))\n",
    "df_train['text'] = df_train['text'].apply(lambda x : x.lower())\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_emoji(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_url(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : seperate_alphanumeric(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : decontraction(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_html(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : remove_mentions(x))\n",
    "df_test['text'] = df_test['text'].apply(lambda x : x.lower())\n",
    "\n",
    "df_train['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T20:22:07.077864400Z",
     "start_time": "2023-08-09T20:22:06.498079100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index dimension must be 1 or 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m tfidf_vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer(\n\u001B[0;32m      2\u001B[0m     min_df\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m      3\u001B[0m     stop_words\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m     ngram_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      7\u001B[0m tfidf_matrix \u001B[38;5;241m=\u001B[39m tfidf_vectorizer\u001B[38;5;241m.\u001B[39mfit_transform(\n\u001B[0;32m      8\u001B[0m     pd\u001B[38;5;241m.\u001B[39mconcat(\n\u001B[1;32m----> 9\u001B[0m         [\u001B[43mdf_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, df_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m     10\u001B[0m     )\n\u001B[0;32m     11\u001B[0m )\n\u001B[0;32m     12\u001B[0m target \u001B[38;5;241m=\u001B[39m df_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\_index.py:47\u001B[0m, in \u001B[0;36mIndexMixin.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m---> 47\u001B[0m     row, col \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m# Dispatch to specialized methods.\u001B[39;00m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, INT_TYPES):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\_index.py:159\u001B[0m, in \u001B[0;36mIndexMixin._validate_indices\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    157\u001B[0m         row \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m M\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(row, \u001B[38;5;28mslice\u001B[39m):\n\u001B[1;32m--> 159\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_asindices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mM\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isintlike(col):\n\u001B[0;32m    162\u001B[0m     col \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(col)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\scipy\\sparse\\_index.py:183\u001B[0m, in \u001B[0;36mIndexMixin._asindices\u001B[1;34m(self, idx, length)\u001B[0m\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minvalid index\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m--> 183\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIndex dimension must be 1 or 2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[1;31mIndexError\u001B[0m: Index dimension must be 1 or 2"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(\n",
    "\n",
    ")\n",
    "target = df_train['target']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T20:31:23.253540Z",
     "start_time": "2023-08-09T20:31:23.204540900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m df_train \u001B[38;5;241m=\u001B[39m tfidf_matrix[:\u001B[38;5;241m7613\u001B[39m,:]\n\u001B[1;32m----> 2\u001B[0m df_train \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(df_train, \u001B[43mtarget\u001B[49m)\n\u001B[0;32m      3\u001B[0m df_train\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_processed.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = tfidf_matrix[:7613,:]\n",
    "df_train = pd.concat(df_train, target)\n",
    "df_train.to_csv('train_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T20:29:51.666550200Z",
     "start_time": "2023-08-09T20:29:50.632654500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = tfidf_matrix[7613:,:]\n",
    "df_test.to_csv('test_processed.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
